<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="python, scala, spark, hive, hbase, hadoop, tensorflow, flink, 机器学习, 深度学习, 算法"><title>【Tensorflow2】Estimator使用流程——以Titanic预测任务为例 | Ritchie's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '87868a9c378cabc27812ae2d1ebfbb13';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【Tensorflow2】Estimator使用流程——以Titanic预测任务为例</h1><a id="logo" href="/.">Ritchie's Blog</a><p class="description">点滴记录，技术提升进程</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-list"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于我</i></a><a href="/timeline/"><i class="fa fa-history"> 大事记</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【Tensorflow2】Estimator使用流程——以Titanic预测任务为例</h1><div class="post-meta">Feb 25, 2020<span> | </span><span class="category"><a href="/categories/tensorflow/">tensorflow</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><blockquote>
<p>Estimator&#x662F;Tensorflow&#x5B8C;&#x6574;&#x6A21;&#x578B;&#x7684;&#x9AD8;&#x7EA7;&#x8868;&#x793A;&#xFF0C;&#x5B83;&#x88AB;&#x8BBE;&#x8BA1;&#x7528;&#x4E8E;&#x8F7B;&#x677E;&#x6269;&#x5C55;&#x548C;&#x5F02;&#x6B65;&#x8BAD;&#x7EC3;&#x3002;</p>
</blockquote>
<p>&#x8FD9;&#x53E5;&#x8BDD;&#x662F;&#x5B98;&#x65B9;&#x6587;&#x6863;&#x4E0A;&#x7684;&#x63CF;&#x8FF0;&#xFF0C;&#x6211;&#x89C9;&#x5F97;&#x8BF4;&#x7684;&#x633A;&#x5BF9;&#x7684;&#x3002;&#x4E3A;&#x4E86;&#x66F4;&#x76F4;&#x89C2;&#x7684;&#x4F53;&#x4F1A;&#x8FD9;&#x53E5;&#x8BDD;&#xFF0C;&#x8FD9;&#x91CC;&#x6211;&#x4EE5;Kaggle&#x7ECF;&#x5178;&#x7684;&#x5165;&#x95E8;&#x7EC3;&#x4E60;Titanic&#x4E3A;&#x4F8B;&#xFF0C;&#x4E3A;&#x5927;&#x5BB6;&#x5448;&#x73B0;Estimator&#x7684;&#x5B8C;&#x6574;&#x4F7F;&#x7528;&#x6D41;&#x7A0B;&#x3002;</p>
<a id="more"></a>
<h1>Titanic&#x4EFB;&#x52A1;&#x4E0E;&#x6570;&#x636E;&#x8BF4;&#x660E;</h1>
<p>&#x5F53;&#x5B8C;&#x6210;Kaggle&#x7684;&#x6CE8;&#x518C;&#x4E4B;&#x540E;&#xFF0C;&#x4F60;&#x9700;&#x8981;&#x5B8C;&#x6210;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x5165;&#x95E8;&#x7EA7;&#x4EFB;&#x52A1;&#x5C31;&#x662F;<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Titanic</a>&#x3002;<br>
&#x8FD9;&#x4E2A;&#x4EFB;&#x52A1;&#x7684;&#x76EE;&#x7684;&#x662F;&#x9884;&#x6D4B;&#x4E58;&#x5BA2;&#x662F;&#x5426;&#x4F1A;&#x5B58;&#x6D3B;&#x3002;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x4F1A;&#x63D0;&#x4F9B;&#x4E58;&#x5BA2;&#x7684;&#x4E00;&#x4E9B;&#x57FA;&#x7840;&#x7279;&#x5F81;&#xFF0C;&#x7528;&#x4E8E;&#x6784;&#x5EFA;&#x6A21;&#x578B;&#x8F93;&#x5165;&#x6570;&#x636E;&#x3002;&#x8FD9;&#x4E9B;&#x7279;&#x5F81;&#x5305;&#x62EC;&#x4E86;&#xFF1A;</p>
<ol>
<li>PassengerId: &#x4E58;&#x5BA2;&#x7684;ID</li>
<li>Survived: &#x4E58;&#x5BA2;&#x662F;&#x5426;&#x5B58;&#x6D3B;&#x3002;0&#x8868;&#x793A;&#x6CA1;&#x6709;&#x5B58;&#x6D3B;&#xFF0C;1&#x8868;&#x793A;&#x5B58;&#x6D3B;</li>
<li>Pclass: &#x4E58;&#x5BA2;&#x7684;&#x8239;&#x7968;&#x7B49;&#x7EA7;&#x3002;&#x5305;&#x542B;1&#x3001;2&#x3001;3&#x7EA7;&#x3002;</li>
<li>Name: &#x4E58;&#x5BA2;&#x59D3;&#x540D;&#x3002;</li>
<li>Sex: &#x4E58;&#x5BA2;&#x6027;&#x522B;&#x3002;&#x5305;&#x62EC;male&#x548C;female&#x3002;</li>
<li>Age: &#x4E58;&#x5BA2;&#x5E74;&#x9F84;&#x3002;</li>
<li>SibSp: &#x548C;&#x4E58;&#x5BA2;&#x4E00;&#x8D77;&#x5728;&#x8239;&#x4E0A;&#x7684;&#x4EB2;&#x4EBA;&#x6570;&#xFF08;&#x5305;&#x62EC;&#x5144;&#x5F1F;&#x59D0;&#x59B9;&#x914D;&#x5076;&#xFF09;&#x3002;</li>
<li>Parch: &#x548C;&#x4E58;&#x5BA2;&#x4E00;&#x8D77;&#x5728;&#x8239;&#x4E0A;&#x7684;&#x4EB2;&#x4EBA;&#x6570;&#xFF08;&#x5305;&#x62EC;&#x7236;&#x6BCD;&#x548C;&#x5B50;&#x5973;&#xFF09;&#x3002;</li>
<li>Ticket: &#x4E58;&#x5BA2;&#x7684;&#x8239;&#x7968;&#x7F16;&#x53F7;&#x3002;</li>
<li>Fare: &#x4E58;&#x5BA2;&#x7684;&#x8239;&#x7968;&#x4EF7;&#x683C;&#x3002;</li>
<li>Cabin: &#x4E58;&#x5BA2;&#x7684;&#x8239;&#x8231;&#x7F16;&#x53F7;&#x3002;</li>
<li>Embarked: &#x4E58;&#x5BA2;&#x7684;&#x4E0A;&#x8239;&#x6E2F;&#x53E3;&#x3002;&#x5305;&#x62EC;C(&#x745F;&#x5821;)&#x3001;Q(&#x7687;&#x540E;&#x9547;)&#x3001;S(&#x5357;&#x5B89;&#x666E;&#x987F;)</li>
</ol>
<p>&#x4E0A;&#x9762;&#x7684;PassengerId&#x4F5C;&#x4E3A;&#x7D22;&#x5F15;&#x5217;&#xFF0C;&#x4E0D;&#x53C2;&#x4E0E;&#x5230;&#x6A21;&#x578B;&#x7279;&#x5F81;&#x6784;&#x5EFA;&#x3002;Survived&#x4E3A;&#x6A21;&#x578B;&#x9884;&#x6D4B;&#x7684;&#x6807;&#x7B7E;&#x5217;&#x3002;&#x5F88;&#x660E;&#x663E;&#x8FD9;&#x662F;&#x4E2A;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x3002;&#x8BDD;&#x4E0D;&#x591A;&#x8BF4;&#xFF0C;&#x63A5;&#x4E0B;&#x6765;&#x6211;&#x5C06;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x7B80;&#x5355;&#x7684;&#x9884;&#x5904;&#x7406;&#xFF0C;&#x4EE5;&#x65B9;&#x4FBF;&#x540E;&#x9762;&#x7684;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x3002;</p>
<h1>&#x6570;&#x636E;&#x9884;&#x5904;&#x7406;</h1>
<p>&#x7531;&#x4E8E;&#x6211;&#x540E;&#x9762;&#x4F1A;&#x4F7F;&#x7528;FeatureColumn&#x6765;&#x5BF9;&#x7279;&#x5F81;&#x8FDB;&#x884C;&#x7F16;&#x7801;&#xFF0C;&#x8FD9;&#x91CC;&#x7684;&#x9884;&#x5904;&#x7406;&#x53EA;&#x662F;&#x8FDB;&#x884C;&#x7B80;&#x5355;&#x7684;&#x7F3A;&#x5931;&#x503C;&#x586B;&#x5145;&#x3002;&#x901A;&#x8FC7;&#x5BF9;&#x6BCF;&#x4E2A;&#x7279;&#x5F81;&#x5217;&#x53D6;&#x503C;&#x7684;&#x7EDF;&#x8BA1;&#xFF0C;&#x53D1;&#x73B0;<code>Age</code>&#x3001;<code>Fare</code>&#x3001;<code>Cabin</code>&#x3001;<code>Embarked</code>&#x8FD9;&#x56DB;&#x4E2A;&#x7279;&#x5F81;&#x5217;&#x4E2D;&#x5B58;&#x5728;&#x53D6;&#x503C;&#x7F3A;&#x5931;&#x7684;&#x60C5;&#x51B5;&#x3002;&#x8FD9;&#x91CC;&#x6211;&#x76F4;&#x63A5;&#x91C7;&#x7528;&#x7ED9;&#x7F3A;&#x5931;&#x8BB0;&#x5F55;&#x7EDF;&#x4E00;&#x586B;&#x5145;&#x76F8;&#x540C;&#x7F3A;&#x5931;&#x6807;&#x5FD7;&#x7B26;&#x7684;&#x65B9;&#x6CD5;&#x6765;&#x5904;&#x7406;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_process</span><span class="params">(data)</span>:</span></span><br><span class="line">    data[<span class="string">&apos;Age&apos;</span>] = pd.to_numeric(data[<span class="string">&apos;Age&apos;</span>].fillna(<span class="number">-1</span>), errors=<span class="string">&apos;raise&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Fare&apos;</span>] = pd.to_numeric(data[<span class="string">&apos;Fare&apos;</span>].fillna(<span class="number">-1</span>), errors=<span class="string">&apos;raise&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Cabin&apos;</span>] = data[<span class="string">&apos;Cabin&apos;</span>].fillna(<span class="string">&apos;nan&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Embarked&apos;</span>] = data[<span class="string">&apos;Embarked&apos;</span>].fillna(<span class="string">&apos;nan&apos;</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>&#x7F3A;&#x5931;&#x503C;&#x5904;&#x7406;&#x7684;&#x65B9;&#x6CD5;&#x6709;&#x5F88;&#x591A;&#xFF0C;&#x8FD9;&#x91CC;&#x6211;&#x53EA;&#x662F;&#x4E3A;&#x4E86;&#x5448;&#x73B0;Estimator&#x7684;&#x5B8C;&#x6574;&#x4F7F;&#x7528;&#x6D41;&#x7A0B;&#xFF0C;&#x5BF9;&#x4E8E;&#x6A21;&#x578B;&#x7684;&#x51C6;&#x786E;&#x7387;&#x5E76;&#x4E0D;&#x662F;&#x672C;&#x7BC7;&#x6587;&#x7AE0;&#x7684;&#x5173;&#x6CE8;&#x70B9;&#x3002;</p>
<h1>input_fn</h1>
<p>&#x8FD9;&#x91CC;&#x7528;&#x6765;&#x6784;&#x5EFA;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#x65F6;&#x7684;&#x8F93;&#x5165;&#x51FD;&#x6570;&#x3002;&#x7531;&#x4E8E;&#x662F;&#x5305;&#x542B;&#x4E86;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#x4E24;&#x90E8;&#x5206;&#xFF0C;&#x5C31;&#x9700;&#x8981;&#x5BF9;&#x6570;&#x636E;&#x96C6;&#x8FDB;&#x884C;&#x5206;&#x9694;&#x3002;<br>
Titanic&#x7684;&#x6570;&#x636E;&#x96C6;&#x4E0B;&#x8F7D;&#x5730;&#x5740;&#x5728;<a href="https://www.kaggle.com/c/titanic/download/GQf0y8ebHO0C4JXscPPp%2Fversions%2FXkNkvXwqPPVG0Qt3MtQT%2Ffiles%2Ftrain.csv" target="_blank" rel="noopener">&#x8FD9;&#x91CC;</a><br>
&#x6211;&#x4F1A;&#x6309;&#x7167;8:2&#x7684;&#x6BD4;&#x4F8B;&#x6765;&#x83B7;&#x5F97;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x96C6;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data</span><span class="params">(path, test_rate)</span>:</span></span><br><span class="line">    data = pd.read_csv(filepath_or_buffer=path)</span><br><span class="line">    data = data_process(data)</span><br><span class="line">    test_data = data.sample(frac=test_rate)</span><br><span class="line">    train_data = pd.concat([data, test_data], axis=<span class="number">0</span>)</span><br><span class="line">    train_data.drop_duplicates(keep=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> train_data, test_data</span><br><span class="line"></span><br><span class="line">train_data, test_data = split(<span class="string">&apos;./train.csv&apos;</span>, test_rate=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>&#x4E0A;&#x9762;&#x8FD9;&#x79CD;&#x5212;&#x5206;&#x8FD8;&#x662F;&#x6BD4;&#x8F83;&#x50BB;&#x7684;&#xFF0C;sklearn&#x4E2D;&#x63D0;&#x4F9B;&#x4E86;&#x5F88;&#x591A;&#x66F4;&#x597D;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x6709;&#x5174;&#x8DA3;&#x7684;&#x670B;&#x53CB;&#x53EF;&#x4EE5;&#x53BB;&#x7814;&#x7A76;&#x4E00;&#x4E0B;&#x3002;</p>
<p>&#x63A5;&#x4E0B;&#x6765;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x5165;&#x51FD;&#x6570;&#x4E86;&#x3002;&#x6211;&#x5C06;&#x6839;&#x636E;&#x5177;&#x4F53;&#x7684;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x6765;&#x8BF4;&#x660E;&#x4E00;&#x4E0B;&#x6784;&#x5EFA;&#x903B;&#x8F91;&#xFF1A;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data, batch_size, is_training, num_epochs=<span class="number">1</span>)</span>:</span></span><br><span class="line">    labels = data.pop(<span class="string">&apos;Survived&apos;</span>)</span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices((dict(data), labels))</span><br><span class="line">    <span class="keyword">if</span> is_training:</span><br><span class="line">        dataset = dataset.shuffle(buffer_size=batch_size)</span><br><span class="line">        dataset = dataset.repeat(count=num_epochs)</span><br><span class="line">    <span class="keyword">return</span> dataset.batch(batch_size=batch_size)</span><br></pre></td></tr></table></figure>
<p>&#x8FD9;&#x91CC;&#x7684;&#x8F93;&#x5165;&#x5305;&#x62EC;&#x4E86;&#x4E0A;&#x9762;&#x5207;&#x5272;&#x597D;&#x7684;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x548C;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#xFF0C;&#x5C31;&#x662F;&#x53C2;&#x6570;data&#x3002;<br>
&#x8FD8;&#x9700;&#x8981;&#x5B9A;&#x4E49;&#x6570;&#x636E;&#x7684;&#x6279;&#x6B21;&#x5927;&#x5C0F;(batch_size)&#xFF0C;Estimator&#x91C7;&#x7528;&#x5C0F;&#x6279;&#x91CF;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7684;&#x65B9;&#x6CD5;&#x6765;&#x8FDB;&#x884C;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x3002;<br>
is_training&#x7528;&#x6765;&#x533A;&#x5206;&#x4EFB;&#x52A1;&#x7C7B;&#x578B;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x51B3;&#x5B9A;&#x662F;&#x5426;&#x9700;&#x8981;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;shuffle&#x64CD;&#x4F5C;&#x3002;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;shuffle&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x4E00;&#x5B9A;&#x7A0B;&#x5EA6;&#x4E0A;&#x52A0;&#x5FEB;&#x6A21;&#x578B;&#x6536;&#x655B;&#x901F;&#x5EA6;&#x3002;<br>
&#x8BAD;&#x7EC3;&#x4EFB;&#x52A1;&#x4E00;&#x822C;&#x4F1A;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x591A;&#x8F6E;&#x8FED;&#x4EE3;&#xFF0C;&#x901A;&#x8FC7;num_epochs&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x3002;</p>
<p>&#x8FD9;&#x4E00;&#x90E8;&#x5206;&#x4E3B;&#x8981;&#x4F7F;&#x7528;tf.data&#x7684;API&#xFF0C;&#x66F4;&#x591A;&#x5185;&#x5BB9;&#x53EF;&#x4EE5;&#x53C2;&#x8003;<a href="https://www.ritchie.top/2019/12/28/tensorflow-dataset/">Dataset&#x7B80;&#x660E;&#x6559;&#x7A0B;</a></p>
<h1>feature_column</h1>
<p>&#x539F;&#x59CB;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x4E2D;&#x65E2;&#x6709;&#x8FDE;&#x7EED;&#x7279;&#x5F81;&#x4E5F;&#x6709;&#x79BB;&#x6563;&#x7279;&#x5F81;&#xFF0C;&#x8FD9;&#x5C31;&#x9700;&#x8981;&#x6211;&#x7ED9;&#x6BCF;&#x4E2A;&#x7279;&#x5F81;&#x7684;&#x5B9A;&#x4E49;&#x5904;&#x7406;&#x903B;&#x8F91;&#xFF0C;&#x6765;&#x5B8C;&#x6210;&#x539F;&#x59CB;&#x6570;&#x636E;&#x5411;&#x6A21;&#x578B;&#x771F;&#x6B63;&#x7528;&#x4E8E;&#x8BA1;&#x7B97;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6570;&#x503C;&#x5316;&#x8F6C;&#x6362;&#x3002;<br>
&#x6211;&#x8FD9;&#x91CC;&#x5E76;&#x4E0D;&#x6253;&#x7B97;&#x4F7F;&#x7528;&#x6240;&#x6709;&#x7684;&#x7279;&#x5F81;&#x5217;&#xFF0C;&#x53EA;&#x7528;&#x5176;&#x4E2D;&#x7684;&#x51E0;&#x4E2A;&#x8FDB;&#x884C;&#x4E3E;&#x4F8B;&#x5373;&#x53EF;&#x3002;</p>
<ul>
<li>&#x53EF;&#x4EE5;&#x7A77;&#x4E3E;&#x7684;&#x6807;&#x79F0;&#x7279;&#x5F81;</li>
</ul>
<p>Sex&#x3001;Pclass&#x3001;Embarked&#x8FD9;&#x4E09;&#x4E2A;&#x7279;&#x5F81;&#x7684;&#x53D6;&#x503C;&#x4E0D;&#x591A;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;list&#x8FDB;&#x884C;&#x53EF;&#x80FD;&#x53D6;&#x503C;&#x7684;&#x7BA1;&#x7406;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sex = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">    key=<span class="string">&apos;Sex&apos;</span>, vocabulary_list=[<span class="string">&apos;male&apos;</span>, <span class="string">&apos;female&apos;</span>])</span><br><span class="line">pclass = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">    key=<span class="string">&apos;Pclass&apos;</span>, vocabulary_list=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">embarked = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">    key=<span class="string">&apos;Embarked&apos;</span>, vocabulary_list=[<span class="string">&apos;S&apos;</span>, <span class="string">&apos;C&apos;</span>, <span class="string">&apos;Q&apos;</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>&#x65E0;&#x6CD5;&#x7A77;&#x4E3E;&#x7684;&#x6807;&#x79F0;&#x7279;&#x5F81;</li>
</ul>
<p>Ticket&#x3001;Cabin&#x8FD9;&#x4E24;&#x4E2A;&#x7279;&#x5F81;&#x7684;&#x53D6;&#x503C;&#x6BD4;&#x8F83;&#x591A;&#xFF0C;&#x65E0;&#x6CD5;&#x4F7F;&#x7528;list&#x6765;&#x8FDB;&#x884C;&#x53EF;&#x80FD;&#x53D6;&#x503C;&#x7684;&#x7BA1;&#x7406;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ticket = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">    key=<span class="string">&apos;Ticket&apos;</span>, hash_bucket_size=<span class="number">1000</span>)</span><br><span class="line">cabin = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">    key=<span class="string">&apos;Cabin&apos;</span>, hash_bucket_size=<span class="number">300</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>&#x8FDE;&#x7EED;&#x7279;&#x5F81;</li>
</ul>
<p>SibSp&#x3001;Parch&#x90FD;&#x662F;&#x6570;&#x503C;&#x7C7B;&#x578B;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x7528;&#x5230;&#x6A21;&#x578B;&#x4E2D;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sibsp = tf.feature_column.numeric_column(key=<span class="string">&apos;SibSp&apos;</span>)</span><br><span class="line">parch = tf.feature_column.numeric_column(key=<span class="string">&apos;Parch&apos;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>&#x6570;&#x503C;&#x7C7B;&#x578B;&#x7279;&#x5F81;&#x7684;&#x79BB;&#x6563;&#x5316;&#x5904;&#x7406;</li>
</ul>
<p>Age&#x3001;Fare&#x4E5F;&#x662F;&#x6570;&#x503C;&#x7C7B;&#x578B;&#xFF0C;&#x4F46;&#x662F;Age&#x7279;&#x5F81;&#x4E0D;&#x5177;&#x6709;&#x8BA1;&#x7B97;&#x610F;&#x4E49;&#xFF0C;Fare&#x7279;&#x5F81;&#x7684;&#x53D6;&#x503C;&#x5DEE;&#x5F02;&#x6027;&#x8F83;&#x5927;&#x3002;&#x9488;&#x5BF9;&#x8FD9;&#x4E24;&#x4E2A;&#x7279;&#x5F81;&#x6211;&#x8FDB;&#x884C;&#x5206;&#x6876;&#x5904;&#x7406;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">raw_age = tf.feature_column.numeric_column(key=<span class="string">&apos;Age&apos;</span>)</span><br><span class="line">age = tf.feature_column.bucketized_column(</span><br><span class="line">    source_column=raw_age, boundaries=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">18</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>])</span><br><span class="line">raw_fare = tf.feature_column.numeric_column(key=<span class="string">&apos;Fare&apos;</span>)</span><br><span class="line">fare = tf.feature_column.bucketized_column(</span><br><span class="line">    source_column=raw_fare, boundaries=[<span class="number">0</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">60</span>, <span class="number">120</span>])</span><br></pre></td></tr></table></figure>
<p>&#x8FD9;&#x91CC;&#x6211;&#x6682;&#x65F6;&#x53EA;&#x4F7F;&#x7528;&#x4E0A;&#x9762;&#x8FD9;&#x4E9B;&#x7279;&#x5F81;&#xFF0C;&#x5B8C;&#x6574;&#x7684;&#x5904;&#x7406;&#x903B;&#x8F91;&#x5982;&#x4E0B;&#xFF1A;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_column</span><span class="params">()</span>:</span></span><br><span class="line">    sex = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Sex&apos;</span>, vocabulary_list=[<span class="string">&apos;male&apos;</span>, <span class="string">&apos;female&apos;</span>])</span><br><span class="line">    pclass = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Pclass&apos;</span>, vocabulary_list=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    embarked = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Embarked&apos;</span>, vocabulary_list=[<span class="string">&apos;S&apos;</span>, <span class="string">&apos;C&apos;</span>, <span class="string">&apos;Q&apos;</span>])</span><br><span class="line">    ticket = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">        key=<span class="string">&apos;Ticket&apos;</span>, hash_bucket_size=<span class="number">1000</span>)</span><br><span class="line">    cabin = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">        key=<span class="string">&apos;Cabin&apos;</span>, hash_bucket_size=<span class="number">300</span>)</span><br><span class="line">    sibsp = tf.feature_column.numeric_column(key=<span class="string">&apos;SibSp&apos;</span>)</span><br><span class="line">    parch = tf.feature_column.numeric_column(key=<span class="string">&apos;Parch&apos;</span>)</span><br><span class="line">    raw_age = tf.feature_column.numeric_column(key=<span class="string">&apos;Age&apos;</span>)</span><br><span class="line">    age = tf.feature_column.bucketized_column(</span><br><span class="line">        source_column=raw_age, boundaries=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">18</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>])</span><br><span class="line">    raw_fare = tf.feature_column.numeric_column(key=<span class="string">&apos;Fare&apos;</span>)</span><br><span class="line">    fare = tf.feature_column.bucketized_column(</span><br><span class="line">        source_column=raw_fare, boundaries=[<span class="number">0</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">60</span>, <span class="number">120</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=sex, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=pclass, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=embarked, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=ticket, dimension=<span class="number">10</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=cabin, dimension=<span class="number">8</span>),</span><br><span class="line">        sibsp, parch,</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=age, dimension=<span class="number">3</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=fare, dimension=<span class="number">3</span>)</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>
<p>&#x5728;&#x6700;&#x540E;&#x7684;&#x8FD4;&#x56DE;&#x7279;&#x5F81;&#x5217;&#x8868;&#x4E2D;&#xFF0C;&#x6211;&#x5BF9;&#x6240;&#x6709;&#x7684;&#x79BB;&#x6563;&#x5316;&#x7279;&#x5F81;&#x5217;&#x8FDB;&#x884C;&#x4E86;Embedding&#x5904;&#x7406;&#xFF0C;&#x4ECE;&#x800C;&#x5C06;&#x6700;&#x7EC8;&#x7684;&#x6240;&#x6709;&#x7279;&#x5F81;&#x5217;&#x90FD;&#x8FDB;&#x884C;&#x4E86;&#x6570;&#x503C;&#x5316;&#x8F6C;&#x6362;&#x3002;</p>
<h1>Estimator&#x6A21;&#x578B;</h1>
<p>Tensorflow&#x5B98;&#x65B9;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x4E9B;&#x5F00;&#x7BB1;&#x5373;&#x7528;&#x7684;Estimator&#x6A21;&#x578B;&#xFF0C;&#x8FD9;&#x91CC;&#x6211;&#x4F7F;&#x7528;&#x5176;&#x4E2D;&#x7684;DNNClassifier&#x6A21;&#x578B;&#x6765;&#x8FDB;&#x884C;&#x6B64;&#x6B21;&#x4EFB;&#x52A1;&#x7684;&#x9884;&#x6D4B;&#x3002;&#x5173;&#x4E8E;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x81EA;&#x5B9A;&#x4E49;Estimator&#x6A21;&#x578B;&#xFF0C;&#x540E;&#x7EED;&#x6211;&#x8FD8;&#x4F1A;&#x518D;&#x5206;&#x4EAB;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = tf.estimator.DNNClassifier(feature_columns=feature_column(),</span><br><span class="line">                                   activation_fn=<span class="string">&apos;relu&apos;</span>,</span><br><span class="line">                                   batch_norm=<span class="literal">True</span>,</span><br><span class="line">                                   dropout=<span class="number">0.7</span>,</span><br><span class="line">                                   hidden_units=[<span class="number">256</span>, <span class="number">128</span>, <span class="number">64</span>],</span><br><span class="line">                                   optimizer=<span class="string">&apos;Adam&apos;</span>,</span><br><span class="line">                                   model_dir=<span class="string">&apos;./model&apos;</span>,</span><br><span class="line">                                   n_classes=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>&#x8FD9;&#x6837;&#x5C31;&#x5B9A;&#x4E49;&#x597D;&#x4E86;&#x4E00;&#x4E2A;DNN&#x4E8C;&#x5206;&#x7C7B;&#x6A21;&#x578B;&#xFF0C;&#x91CC;&#x9762;&#x7684;&#x5F88;&#x591A;&#x53C2;&#x6570;&#x90FD;&#x53EF;&#x4EE5;&#x8C03;&#x6574;&#x3002;&#x5173;&#x4E8E;&#x6A21;&#x578B;&#x8C03;&#x4F18;&#x7684;&#x8FD9;&#x91CC;&#x5C31;&#x4E0D;&#x8BF4;&#x4E86;&#x3002;</p>
<h1>&#x8BAD;&#x7EC3;&#x4E0E;&#x8BC4;&#x4F30;</h1>
<p>Estimator&#x8BBE;&#x8BA1;&#x4E86;&#x4E00;&#x5957;&#x975E;&#x5E38;&#x65B9;&#x4FBF;&#x7684;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#x67B6;&#x6784;&#xFF0C;&#x80FD;&#x591F;&#x5B9E;&#x73B0;&#x4E00;&#x5957;&#x6A21;&#x578B;&#x4EE3;&#x7801;&#x65E0;&#x7F1D;&#x5730;&#x5728;&#x5355;&#x673A;&#x548C;&#x5206;&#x5E03;&#x5F0F;&#x73AF;&#x5883;&#x4E0B;&#x4EFB;&#x610F;&#x5207;&#x6362;&#x3002;&#x4EBA;&#x6027;&#x5316;&#x7684;&#x65B9;&#x6CD5;&#x8BBE;&#x8BA1;&#x4E5F;&#x8BA9;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#x53D8;&#x5F97;&#x66F4;&#x52A0;&#x76F4;&#x89C2;&#x7B80;&#x5355;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_spec = tf.estimator.TrainSpec(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: input_fn(train_input, <span class="number">100</span>, <span class="literal">True</span>, <span class="number">50</span>), max_steps=<span class="literal">None</span>)</span><br><span class="line">eval_spec = tf.estimator.EvalSpec(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: input_fn(test_input, <span class="number">100</span>, <span class="literal">False</span>, <span class="number">1</span>), steps=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>&#x901A;&#x8FC7;&#x5B9A;&#x4E49;TrainSpec&#x548C;EvalSpec&#x6765;&#x914D;&#x7F6E;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#x7684;&#x53C2;&#x6570;&#x3002;&#x8FD9;&#x91CC;&#x4E3B;&#x8981;&#x7528;&#x5230;&#x7684;&#x5C31;&#x662F;input_fn&#x548C;&#x6700;&#x5927;&#x8BAD;&#x7EC3;&#x6216;&#x8BC4;&#x4F30;&#x6B65;&#x6570;&#x3002;</p>
<p>&#x89E6;&#x53D1;&#x6A21;&#x578B;&#x7684;&#x8BAD;&#x7EC3;&#x548C;&#x8BC4;&#x4F30;&#xFF0C;&#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;&#xFF1A;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.estimator.train_and_evaluate(</span><br><span class="line">    estimator=model, train_spec=train_spec, eval_spec=eval_spec)</span><br></pre></td></tr></table></figure>
<p>&#x4F7F;&#x7528;&#x5230;&#x7684;&#x53C2;&#x6570;&#x90FD;&#x662F;&#x4E0A;&#x9762;&#x5DF2;&#x7ECF;&#x5B9A;&#x4E49;&#x597D;&#x7684;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x628A;&#x5B83;&#x4EEC;&#x6346;&#x7ED1;&#x5230;&#x4E00;&#x8D77;&#x5373;&#x53EF;&#x3002;</p>
<h1>&#x5B8C;&#x6574;&#x4EE3;&#x7801;&#x548C;&#x65E5;&#x5FD7;</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_process</span><span class="params">(data)</span>:</span></span><br><span class="line">    data[<span class="string">&apos;Age&apos;</span>] = pd.to_numeric(data[<span class="string">&apos;Age&apos;</span>].fillna(<span class="number">-1</span>), errors=<span class="string">&apos;raise&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Fare&apos;</span>] = pd.to_numeric(data[<span class="string">&apos;Fare&apos;</span>].fillna(<span class="number">-1</span>), errors=<span class="string">&apos;raise&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Cabin&apos;</span>] = data[<span class="string">&apos;Cabin&apos;</span>].fillna(<span class="string">&apos;nan&apos;</span>)</span><br><span class="line">    data[<span class="string">&apos;Embarked&apos;</span>] = data[<span class="string">&apos;Embarked&apos;</span>].fillna(<span class="string">&apos;nan&apos;</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data</span><span class="params">(path, test_rate)</span>:</span></span><br><span class="line">    data = pd.read_csv(filepath_or_buffer=path)</span><br><span class="line">    data = data_process(data)</span><br><span class="line">    test_data = data.sample(frac=test_rate)</span><br><span class="line">    train_data = pd.concat([data, test_data], axis=<span class="number">0</span>)</span><br><span class="line">    train_data.drop_duplicates(keep=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> train_data, test_data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data, batch_size, is_training, num_epochs=<span class="number">1</span>)</span>:</span></span><br><span class="line">    labels = data.pop(<span class="string">&apos;Survived&apos;</span>)</span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices((dict(data), labels))</span><br><span class="line">    <span class="keyword">if</span> is_training:</span><br><span class="line">        dataset = dataset.shuffle(buffer_size=batch_size)</span><br><span class="line">        dataset = dataset.repeat(count=num_epochs)</span><br><span class="line">    <span class="keyword">return</span> dataset.batch(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_column</span><span class="params">()</span>:</span></span><br><span class="line">    sex = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Sex&apos;</span>, vocabulary_list=[<span class="string">&apos;male&apos;</span>, <span class="string">&apos;female&apos;</span>])</span><br><span class="line">    pclass = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Pclass&apos;</span>, vocabulary_list=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    embarked = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=<span class="string">&apos;Embarked&apos;</span>, vocabulary_list=[<span class="string">&apos;S&apos;</span>, <span class="string">&apos;C&apos;</span>, <span class="string">&apos;Q&apos;</span>])</span><br><span class="line">    ticket = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">        key=<span class="string">&apos;Ticket&apos;</span>, hash_bucket_size=<span class="number">1000</span>)</span><br><span class="line">    cabin = tf.feature_column.categorical_column_with_hash_bucket(</span><br><span class="line">        key=<span class="string">&apos;Cabin&apos;</span>, hash_bucket_size=<span class="number">300</span>)</span><br><span class="line">    sibsp = tf.feature_column.numeric_column(key=<span class="string">&apos;SibSp&apos;</span>)</span><br><span class="line">    parch = tf.feature_column.numeric_column(key=<span class="string">&apos;Parch&apos;</span>)</span><br><span class="line">    raw_age = tf.feature_column.numeric_column(key=<span class="string">&apos;Age&apos;</span>)</span><br><span class="line">    age = tf.feature_column.bucketized_column(</span><br><span class="line">        source_column=raw_age, boundaries=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">18</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>])</span><br><span class="line">    raw_fare = tf.feature_column.numeric_column(key=<span class="string">&apos;Fare&apos;</span>)</span><br><span class="line">    fare = tf.feature_column.bucketized_column(</span><br><span class="line">        source_column=raw_fare, boundaries=[<span class="number">0</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">60</span>, <span class="number">120</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=sex, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=pclass, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=embarked, dimension=<span class="number">2</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=ticket, dimension=<span class="number">10</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=cabin, dimension=<span class="number">8</span>),</span><br><span class="line">        sibsp, parch,</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=age, dimension=<span class="number">3</span>),</span><br><span class="line">        tf.feature_column.embedding_column(categorical_column=fare, dimension=<span class="number">3</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">model = tf.estimator.DNNClassifier(feature_columns=feature_column(),</span><br><span class="line">                                   activation_fn=<span class="string">&apos;relu&apos;</span>,</span><br><span class="line">                                   batch_norm=<span class="literal">True</span>,</span><br><span class="line">                                   dropout=<span class="number">0.7</span>,</span><br><span class="line">                                   hidden_units=[<span class="number">256</span>, <span class="number">128</span>, <span class="number">64</span>],</span><br><span class="line">                                   optimizer=<span class="string">&apos;Adam&apos;</span>,</span><br><span class="line">                                   model_dir=<span class="string">&apos;./model&apos;</span>,</span><br><span class="line">                                   n_classes=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">train_input, test_input = split_data(<span class="string">&apos;./train.csv&apos;</span>, test_rate=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">train_spec = tf.estimator.TrainSpec(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: input_fn(train_input, <span class="number">100</span>, <span class="literal">True</span>, <span class="number">50</span>), max_steps=<span class="literal">None</span>)</span><br><span class="line">eval_spec = tf.estimator.EvalSpec(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: input_fn(test_input, <span class="number">100</span>, <span class="literal">False</span>, <span class="number">1</span>), steps=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">tf.estimator.train_and_evaluate(</span><br><span class="line">    estimator=model, train_spec=train_spec, eval_spec=eval_spec)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Using default config.</span><br><span class="line">INFO:tensorflow:Using config: {&apos;_model_dir&apos;: &apos;./model&apos;, &apos;_tf_random_seed&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_save_checkpoints_steps&apos;: None, &apos;_save_checkpoints_secs&apos;: 600, &apos;_session_config&apos;: allow_soft_placement: true</span><br><span class="line">graph_options {</span><br><span class="line">  rewrite_options {</span><br><span class="line">    meta_optimizer_iterations: ONE</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line">, &apos;_keep_checkpoint_max&apos;: 5, &apos;_keep_checkpoint_every_n_hours&apos;: 10000, &apos;_log_step_count_steps&apos;: 100, &apos;_train_distribute&apos;: None, &apos;_device_fn&apos;: None, &apos;_protocol&apos;: None, &apos;_eval_distribute&apos;: None, &apos;_experimental_distribute&apos;: None, &apos;_experimental_max_worker_delay_secs&apos;: None, &apos;_session_creation_timeout_secs&apos;: 7200, &apos;_service&apos;: None, &apos;_cluster_spec&apos;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x145cef290&gt;, &apos;_task_type&apos;: &apos;worker&apos;, &apos;_task_id&apos;: 0, &apos;_global_id_in_cluster&apos;: 0, &apos;_master&apos;: &apos;&apos;, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_is_chief&apos;: True, &apos;_num_ps_replicas&apos;: 0, &apos;_num_worker_replicas&apos;: 1}</span><br><span class="line">INFO:tensorflow:Not using Distribute Coordinator.</span><br><span class="line">INFO:tensorflow:Running training and evaluation locally (non-distributed).</span><br><span class="line">INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.</span><br><span class="line">INFO:tensorflow:Calling model_fn.</span><br><span class="line">WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer&apos;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&apos;s dtype defaults to floatx.</span><br><span class="line"></span><br><span class="line">If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.</span><br><span class="line"></span><br><span class="line">To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&apos;float64&apos;)`. To change just this layer, pass dtype=&apos;float64&apos; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.</span><br><span class="line"></span><br><span class="line">INFO:tensorflow:Done calling model_fn.</span><br><span class="line">INFO:tensorflow:Create CheckpointSaverHook.</span><br><span class="line">INFO:tensorflow:Graph was finalized.</span><br><span class="line">INFO:tensorflow:Running local_init_op.</span><br><span class="line">INFO:tensorflow:Done running local_init_op.</span><br><span class="line">INFO:tensorflow:Saving checkpoints for 0 into ./model/model.ckpt.</span><br><span class="line">INFO:tensorflow:loss = 0.9460948, step = 0</span><br><span class="line">INFO:tensorflow:global_step/sec: 108.812</span><br><span class="line">INFO:tensorflow:loss = 0.5249347, step = 100 (0.920 sec)</span><br><span class="line">INFO:tensorflow:global_step/sec: 215.037</span><br><span class="line">INFO:tensorflow:loss = 0.4911957, step = 200 (0.465 sec)</span><br><span class="line">INFO:tensorflow:global_step/sec: 227.797</span><br><span class="line">INFO:tensorflow:loss = 0.48654288, step = 300 (0.439 sec)</span><br><span class="line">INFO:tensorflow:Saving checkpoints for 357 into ./model/model.ckpt.</span><br><span class="line">INFO:tensorflow:Calling model_fn.</span><br><span class="line">WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer&apos;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&apos;s dtype defaults to floatx.</span><br><span class="line"></span><br><span class="line">If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.</span><br><span class="line"></span><br><span class="line">To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&apos;float64&apos;)`. To change just this layer, pass dtype=&apos;float64&apos; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.</span><br><span class="line"></span><br><span class="line">INFO:tensorflow:Done calling model_fn.</span><br><span class="line">INFO:tensorflow:Starting evaluation at 2020-02-25T13:25:28Z</span><br><span class="line">INFO:tensorflow:Graph was finalized.</span><br><span class="line">INFO:tensorflow:Restoring parameters from ./model/model.ckpt-357</span><br><span class="line">INFO:tensorflow:Running local_init_op.</span><br><span class="line">INFO:tensorflow:Done running local_init_op.</span><br><span class="line">INFO:tensorflow:Finished evaluation at 2020-02-25-13:25:29</span><br><span class="line">INFO:tensorflow:Saving dict for global step 357: accuracy = 0.7303371, accuracy_baseline = 0.6348315, auc = 0.8478557, auc_precision_recall = 0.7938756, average_loss = 0.5330257, global_step = 357, label/mean = 0.36516854, loss = 0.53750694, precision = 0.9047619, prediction/mean = 0.24691269, recall = 0.2923077</span><br><span class="line">INFO:tensorflow:Saving &apos;checkpoint_path&apos; summary for global step 357: ./model/model.ckpt-357</span><br><span class="line">INFO:tensorflow:Loss for final step: 0.46987808.</span><br></pre></td></tr></table></figure>
<h1>&#x6A21;&#x578B;&#x9884;&#x6D4B;</h1>
<p>&#x5B8C;&#x6210;&#x4E86;&#x4E0A;&#x9762;&#x7684;&#x64CD;&#x4F5C;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x5728;<code>./model</code>&#x76EE;&#x5F55;&#x4E0B;&#x5F97;&#x5230;&#x6700;&#x7EC8;&#x7684;&#x6A21;&#x578B;&#x6587;&#x4EF6;&#x3002;&#x5173;&#x4E8E;&#x6A21;&#x578B;&#x6587;&#x4EF6;&#x7684;&#x683C;&#x5F0F;&#x3001;&#x5BFC;&#x51FA;&#x7B49;&#x66F4;&#x591A;&#x5185;&#x5BB9;&#xFF0C;&#x6211;&#x540E;&#x7EED;&#x4E5F;&#x4F1A;&#x529B;&#x4E89;&#x7ED9;&#x5927;&#x5BB6;&#x5206;&#x4EAB;&#x3002;</p>
<p>Titanic&#x7684;&#x9884;&#x6D4B;&#x6570;&#x636E;&#x96C6;&#x4E0B;&#x8F7D;&#x5730;&#x5740;&#x5728;<a href="https://www.kaggle.com/c/titanic/download/GQf0y8ebHO0C4JXscPPp%2Fversions%2FXkNkvXwqPPVG0Qt3MtQT%2Ffiles%2Ftest.csv" target="_blank" rel="noopener">&#x8FD9;&#x91CC;</a></p>
<p>&#x7531;&#x4E8E;&#x9884;&#x6D4B;&#x6570;&#x636E;&#x96C6;&#x5E76;&#x4E0D;&#x5305;&#x542B;<code>Survived</code>&#x5217;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x91CD;&#x65B0;&#x5199;&#x4E86;&#x4E2A;input_fn&#x65B9;&#x6CD5;&#xFF0C;&#x53EA;&#x5305;&#x542B;&#x4E86;&#x6279;&#x6B21;&#x8BBE;&#x7F6E;&#x3002;<br>
&#x9884;&#x6D4B;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#x4E0A;&#x9762;&#x5B9A;&#x4E49;&#x7684;<code>model</code>&#x53D8;&#x91CF;&#xFF0C;&#x8C03;&#x7528;predict&#x65B9;&#x6CD5;&#x5C31;&#x53EF;&#x4EE5;&#x4E86;&#xFF0C;&#x4E0D;&#x80FD;&#x518D;&#x7B80;&#x5355;&#x3002;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">predict_input = data_process(pd.read_csv(<span class="string">&apos;./test.csv&apos;</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_input_fn</span><span class="params">(data, batch_size)</span>:</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(dict(data))</span><br><span class="line">    dataset = dataset.batch(batch_size=batch_size)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line">predictions = model.predict(input_fn=<span class="keyword">lambda</span>: predict_input_fn(predict_input, <span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> prediction, passengerId <span class="keyword">in</span> zip(predictions, predict_input[<span class="string">&apos;PassengerId&apos;</span>]):</span><br><span class="line">    classes = prediction[<span class="string">&apos;classes&apos;</span>][<span class="number">0</span>]</span><br><span class="line">    print(passengerId, int(classes))</span><br></pre></td></tr></table></figure>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://www.ritchie.top/2020/02/25/tensorflow2-estimator-titanic/" data-id="ck71dq495000ldcz6rkcqcgy3" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACuUlEQVR42u3aQXLjMAwEwPz/09kHuGTPAGTWh9YpFcukWgcCHvLnJ75+X673dz795+m7r/e8zvV+3tWFh4eHt370p6GfJnuPfz9agpmNgIeHh3eblyzW7WRP9yf4/Hk+WPDw8PC+gJc0vnnzndw/ewV4eHh438NrMUmT3ZLw8PDwvoGXRwN5eWgj2jYKOZy14OHh4cW8fBfpe/6+sr+Hh4eHt95V32zht8t6G/hGT4uHh4d3gdc+bkLNDxxsilMeYeDh4eGd5c0ihtnP/tmYmwKDh4eHd4PXHhfIt83ydnm2PdbeiYeHh3eWl7fI+f3t5lZ7EKF4KXh4eHhHee3ESQFIkPmy3kbGUe6Lh4eHd5TXsltw3qy38cRj1oKHh4d3lJcXiVm3nocRp0KQIkXGw8PDG/FmJWHWQLfx8ayQPNY9PDw8vKO84gtx45uPtgltPwTNeHh4eBd4bRww2x7Lg4ykxU+CZjw8PLx7vFlhKM5wlZlA+1qL41Z4eHh4R3mb9nT/EO3xgqI1x8PDw7vA20zTvo7hlv9olsfNMDw8PLw1rw1JZ9PPjiDk9zz+Hw8PD+8CbxZAbJb1/OHagwirYAIPDw+v5OXT5EPnDfqslS8OMeDh4eFd4OVLc9su58Vjc0VRBR4eHt5R3myDKl++N8cCNiUHDw8P7zavHXQWyM6i26QwDJtpPDw8vAUvZ7fxxKwwtC07Hh4e3t/zNktzu7Wft86zIoGHh4d3j/dbXslRg3abP2/W68NYeHh4eBd4x37wx3HwLAJuN+FW1QwPDw8v4CXFIBluVk7aZ6gLAx4eHt41Xrsov49f26MD+/ij/hgPDw/vv/LyEnLj0w8xBB4eHt4X8GZb+HlE2x5BWJ2MwMPDw1vwTjW+f/OtujDg4eHhHeW1P/jft9R5JpCMs4mV8fDw8C7w/gEEWsU62W3wOgAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/estimator-titanic/">estimator titanic</a></div><div class="post-nav"><a class="next" href="/2020/01/22/tensorflow2-feature-column/">【Tensorflow2】FeatureColumn简明教程</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: 'e1d9a23bff9cf37a908f',
  clientSecret: 'e940ee66119d68ddc9e557b57925f146ff8e180f',
  repo: 'ritchietop.github.io',
  owner: 'ritchietop',
  admin: ['ritchietop'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/tensorflow-dataset-pipeline/" style="font-size: 15px;">tensorflow dataset pipeline</a> <a href="/tags/dnn-recommendation/" style="font-size: 15px;">dnn recommendation</a> <a href="/tags/markdown/" style="font-size: 15px;">markdown</a> <a href="/tags/tensorflow-tfrecord-sequenceExample/" style="font-size: 15px;">tensorflow tfrecord sequenceExample</a> <a href="/tags/tensorflow-tfrecord-sequenceExample-spark-feature/" style="font-size: 15px;">tensorflow tfrecord sequenceExample spark feature</a> <a href="/tags/estimator-titanic/" style="font-size: 15px;">estimator titanic</a> <a href="/tags/feature-column-embedding-column-FeatureTransformationCache-StateManager/" style="font-size: 15px;">feature_column embedding_column FeatureTransformationCache StateManager</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/tensorflow2-estimator-titanic/">【Tensorflow2】Estimator使用流程——以Titanic预测任务为例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/22/tensorflow2-feature-column/">【Tensorflow2】FeatureColumn简明教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/11/tensorflow2-outline/">【Tensorflow2】从这里开始</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/28/tensorflow-dataset/">【Tensorflow2】Dataset简明教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/25/tensorflow-tfrecord-process/">【Tensorflow2】TFRecord数据读写</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/24/tensorflow-tfrecord-basic_datastruct/">【Tensorflow2】TFRecord数据结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/paper-reading-youtube-dnn-recommendation/">【论文小品】Deep neural networks for YouTube recommendations</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/08/simple-markdown-syntax/">简明Markdown语法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://tf.wiki/" title="简单粗暴 TensorFlow 2.0" target="_blank">简单粗暴 TensorFlow 2.0</a><ul></ul><a href="https://keras.io/zh/" title="Keras: 基于 Python 的深度学习库" target="_blank">Keras: 基于 Python 的深度学习库</a><ul></ul><a href="https://leetcode-cn.com/" title="力扣（LeetCode）" target="_blank">力扣（LeetCode）</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Ritchie's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>